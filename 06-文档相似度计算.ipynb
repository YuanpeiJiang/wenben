{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 高中数学知识\n",
    "本以为自己对这里很熟悉，结果自己写cos计算公式时居然出错了。粘贴到这里，帮助大家回忆高中知识。（a和b是向量）\n",
    "![](img/cos.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cos相似性计算\n",
    "def cosVector(x,y):\n",
    "    result1=0.0\n",
    "    result2=0.0\n",
    "    result3=0.0\n",
    "    for i in range(len(x)):\n",
    "        result1 +=x[i]*y[i]   #sum(a*b)\n",
    "        result2 +=x[i]**2     #sum(a*a)\n",
    "        result3 +=y[i]**2     #sum(b*b)\n",
    "\n",
    "    return str(result1/((result2*result3)**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vect1与vect2相似度为: 0.0\n",
      "vect1与vect3相似度为: 0.8164965809277261\n",
      "vect2与vect3相似度为: 0.5773502691896258\n"
     ]
    }
   ],
   "source": [
    "vect1 = [1,0,1]\n",
    "vect2 = [0,1,0]\n",
    "vect3 = [1,1,1]\n",
    "\n",
    "print(\"vect1与vect2相似度为:\", cosVector(vect1, vect2))\n",
    "print(\"vect1与vect3相似度为:\", cosVector(vect1, vect3))\n",
    "print(\"vect2与vect3相似度为:\", cosVector(vect2, vect3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本相似性计算的思路：\n",
    "\n",
    "1. 抽取语料（所有文档）中的词语，构建词典（词语与数字对应起来）。\n",
    "2. 根据构建的词典对每个文档进行重新编码（将文档转化为向量）。\n",
    "3. 使用余弦计算相似度\n",
    "\n",
    "下面的corpus是我在知乎live随便找到的几个评论，拿来当做测试的例子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = ['xx公司实现xx技术上的突破',\n",
    "          'mm公司技术先进，市场占有率达到该领域9成，正准备上市',\n",
    "          'python是一种特别强大易学的编程语言',\n",
    "          'python这门编程语言，可以用来采集数据/清洗数据/数据分析。。。']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "corpus = ''.join(articles)\n",
    "wordset = set(jieba.lcut(corpus))\n",
    "\n",
    "worddict = dict()\n",
    "num = 0\n",
    "for word in wordset:\n",
    "    worddict[word]=num\n",
    "    num+=1\n",
    "    \n",
    "worddict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "句子转化为向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sen2vec(sen):\n",
    "    vec = [0]*len(worddict)\n",
    "    for word in jieba.lcut(sen):\n",
    "        num = worddict.get(word)\n",
    "        vec[num]+=1\n",
    "    return vec\n",
    "\n",
    "\n",
    "#sen2vec('xx公司实现xx技术上的突破')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.11180339887498948'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sen2vec(articles[0])\n",
    "y = sen2vec(articles[2])\n",
    "cosVector(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建词典-学习语料特征\n",
    "其实在机器学习里，学习语料的所有词语并将其转化为数字，这一步骤叫做特征化。强烈推荐对数据科学感兴趣的童鞋学学scikit-learn库，人工智能咱们小白可能还玩不转，但是调用封装好的机器学习算法，浅显的玩玩机器学习还是没啥难度的。\n",
    "\n",
    "在scikit-learn中，涉及到文本数据特征化的类有sklearn.feature_extraction.text.CountVectorizer 和sklearn.feature_extraction.text.TfidfVectorizer 。我们先以常见的词频统计作为特征抽取的方式开始探索,由于scikit默认使用英文空格作为分词符号，所以处理中文数据前我们要分词并以空格间隔开来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Using cached https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Collecting scikit-learn (from sklearn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/57/8a9889d49d0d77905af5a7524fb2b468d2ef5fc723684f51f5ca63efed0d/scikit_learn-0.21.3-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (10.5MB)\n",
      "\u001b[K     |████████████████████████████████| 10.5MB 47kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.17.2)\n",
      "Collecting joblib>=0.11 (from scikit-learn->sklearn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n",
      "\u001b[K     |████████████████████████████████| 286kB 98kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting scipy>=0.17.0 (from scikit-learn->sklearn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/06/1a696649f4b2e706c509cb9333fdc6331fbe71251cede945f9e1fa13ea34/scipy-1.3.1-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (27.7MB)\n",
      "\u001b[K     |████                            | 3.5MB 26kB/s eta 0:15:169"
     ]
    }
   ],
   "source": [
    "!pip3 install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-5bfb91dba283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjieba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m corpus = [' '.join(jieba.lcut(doc))\n\u001b[1;32m      5\u001b[0m           for doc in corpus]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import jieba\n",
    "\n",
    "corpus = [' '.join(jieba.lcut(doc))\n",
    "          for doc in corpus]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 1 1 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0 0 0 1 0 0 0 1]\n",
      " [0 0 0 1 1 0 0 0 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 1 1 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 1 0 0]]\n",
      "['全面', '分享', '呵呵', '实用', '干货', '很多', '感谢', '无私', '满满', '满满的', '真水', '老师', '讲述']\n"
     ]
    }
   ],
   "source": [
    "wordcounter = CountVectorizer()\n",
    "\n",
    "#学习特征（构建词典）fit  并转化为特征矩阵。\n",
    "matrix=wordcounter.fit_transform(corpus)\n",
    "print(matrix.toarray())\n",
    "\n",
    "#查看下特征与词语对应关系\n",
    "print(wordcounter.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算相似度\n",
    "这里使用scikit提供的cosine-similarity函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.28867513, 0.28867513, 0.25      , 0.        ],\n",
       "       [0.28867513, 1.        , 0.33333333, 0.        , 0.        ],\n",
       "       [0.28867513, 0.33333333, 1.        , 0.        , 0.        ],\n",
       "       [0.25      , 0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们看到这个矩阵是沿着对角线对称的，所以我们只需要看第一行。\n",
    "\n",
    "```\n",
    "第一个评论与第一个评论之间的相似度为1\n",
    "第一个评论与第二个评论的相似度为0.28867513\n",
    "第一个评论与第三个评论的相似度为0.28867513\n",
    "第一个评论与第四个评论的相似度为0.25\n",
    "第一个评论与第四个评论的相似度为0\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
