{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VADER(Valence Aware Dictionary and sEntiment Reasoner)æ˜¯ä¸“é—¨ä¸ºç¤¾äº¤åª’ä½“è¿›è¡Œæƒ…æ„Ÿåˆ†æçš„å·¥å…·ï¼Œç›®å‰ä»…æ”¯æŒè‹±æ–‡æ–‡æœ¬\n",
    "\n",
    "\n",
    "### VADERæƒ…æ„Ÿä¿¡æ¯ä¼šè€ƒè™‘ï¼š\n",
    "- å¦å®šè¡¨è¾¾ï¼ˆå¦‚ï¼Œ\"not good\"ï¼‰\n",
    "- èƒ½è¡¨è¾¾æƒ…æ„Ÿä¿¡æ¯å’Œå¼ºåº¦çš„æ ‡ç‚¹ç¬¦å· (å¦‚, \"Good!!!\")\n",
    "- å¤§å°å†™ç­‰å½¢å¼å¸¦æ¥çš„å¼ºè°ƒï¼Œï¼ˆå¦‚ï¼Œ\"FUNNY.\"ï¼‰\n",
    "- æƒ…æ„Ÿå¼ºåº¦(å¼ºåº¦å¢å¼ºï¼Œå¦‚\"very\" ï¼›å¼ºåº¦å‡å¼±å¦‚ï¼Œ \"kind of\")\n",
    "- è¡¨è¾¾æƒ…æ„Ÿä¿¡æ¯çš„ä¿šè¯­ (å¦‚, 'sux')\n",
    "- èƒ½ä¿®é¥°ä¿šè¯­æƒ…æ„Ÿå¼ºåº¦çš„è¯è¯­ ï¼ˆ'uber'ã€'friggin'ã€'kinda'ï¼‰\n",
    "- è¡¨æƒ…ç¬¦å· :) and :D\n",
    "- utf-8ç¼–ç ä¸­çš„emojæƒ…æ„Ÿè¡¨æƒ…  ï¼ˆ ğŸ’˜ and ğŸ’‹ and ğŸ˜ï¼‰\n",
    "- é¦–å­—æ¯ç¼©ç•¥è¯­ï¼ˆå¦‚ï¼Œ'lol')\n",
    "...\n",
    "\n",
    "VADERç›®å‰åªæ”¯æŒè‹±æ–‡æ–‡æœ¬ï¼Œå¦‚æœæœ‰ç¬¦åˆVADERå½¢å¼çš„ä¸­æ–‡è¯å…¸ï¼Œä¹Ÿèƒ½ä½¿ç”¨VADERå¯¹ä¸­æ–‡è¿›è¡Œåˆ†æã€‚\n",
    "\n",
    "### å®‰è£…VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/9e/c53e1fc61aac5ee490a6ac5e21b1ac04e55a7c2aba647bb8411c9aadf24e/vaderSentiment-3.2.1-py2.py3-none-any.whl (125kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 105kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install vaderSentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨æ–¹æ³•\n",
    "VADERä¼šå¯¹æ–‡æœ¬åˆ†æï¼Œå¾—åˆ°çš„ç»“æœæ˜¯ä¸€ä¸ªå­—å…¸ä¿¡æ¯ï¼ŒåŒ…å«\n",
    "- posï¼Œæ–‡æœ¬ä¸­æ­£é¢ä¿¡æ¯å¾—åˆ†\n",
    "- negï¼Œæ–‡æœ¬ä¸­è´Ÿé¢ä¿¡æ¯å¾—åˆ†\n",
    "- neuï¼Œæ–‡æœ¬ä¸­ä¸­æ€§ä¿¡æ¯å¾—åˆ†\n",
    "- compoundï¼Œæ–‡æœ¬ç»¼åˆæƒ…æ„Ÿå¾—åˆ†\n",
    "\n",
    "### æ–‡æœ¬æƒ…æ„Ÿåˆ†ç±»\n",
    "ä¾æ®compoundç»¼åˆå¾—åˆ†å¯¹æ–‡æœ¬è¿›è¡Œåˆ†ç±»çš„æ ‡å‡†\n",
    "\n",
    "- æ­£é¢:compound score >= 0.05\n",
    "- ä¸­æ€§: -0.05 < compound score < 0.05\n",
    "- è´Ÿé¢: compound score <= -0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.254, 'pos': 0.746, 'compound': 0.8316}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "test = \"VADER is smart, handsome, and funny.\"\n",
    "analyzer.polarity_scores(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™é‡Œæˆ‘ä»¬åªä½¿ç”¨ compound å¾—åˆ†ï¼Œç”¨æ›´å¤šçš„ä¾‹å­è®©å¤§å®¶çœ‹åˆ°æ„Ÿå¹å·ã€ä¿šè¯­ã€emojiã€å¼ºè°ƒç­‰ä¸åŒæ–¹å¼å¯¹å¾—åˆ†çš„å½±å“ã€‚ä¸ºäº†æ–¹ä¾¿ï¼Œæˆ‘ä»¬æƒ³å°†ç»“æœä»¥dataframeæ–¹å¼å±•ç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>VADER is smart, handsome, and funny.</td>\n",
       "      <td>0.8316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>VADER is smart, handsome, and funny!</td>\n",
       "      <td>0.8439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>VADER is very smart, handsome, and funny.</td>\n",
       "      <td>0.8545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>VADER is VERY SMART, handsome, and FUNNY.</td>\n",
       "      <td>0.9227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>VADER is VERY SMART, handsome, and FUNNY!!!</td>\n",
       "      <td>0.9342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>VADER is VERY SMART, uber handsome, and FRIGGI...</td>\n",
       "      <td>0.9469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>VADER is not smart, handsome, nor funny.</td>\n",
       "      <td>-0.7424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>The book was good.</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>At least it isn't a horrible book.</td>\n",
       "      <td>0.4310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>The book was only kind of good.</td>\n",
       "      <td>0.3832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>The plot was good, but the characters are unco...</td>\n",
       "      <td>-0.7042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Today SUX!</td>\n",
       "      <td>-0.5461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Today only kinda sux! But I'll get by, lol</td>\n",
       "      <td>0.5249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Make sure you :) or :D today!</td>\n",
       "      <td>0.8633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Catch utf-8 emoji such as such as ğŸ’˜ and ğŸ’‹ and ğŸ˜</td>\n",
       "      <td>0.7003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Not bad at all</td>\n",
       "      <td>0.4310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  sentiment\n",
       "0                VADER is smart, handsome, and funny.     0.8316\n",
       "1                VADER is smart, handsome, and funny!     0.8439\n",
       "2           VADER is very smart, handsome, and funny.     0.8545\n",
       "3           VADER is VERY SMART, handsome, and FUNNY.     0.9227\n",
       "4         VADER is VERY SMART, handsome, and FUNNY!!!     0.9342\n",
       "5   VADER is VERY SMART, uber handsome, and FRIGGI...     0.9469\n",
       "6            VADER is not smart, handsome, nor funny.    -0.7424\n",
       "7                                  The book was good.     0.4404\n",
       "8                  At least it isn't a horrible book.     0.4310\n",
       "9                     The book was only kind of good.     0.3832\n",
       "10  The plot was good, but the characters are unco...    -0.7042\n",
       "11                                         Today SUX!    -0.5461\n",
       "12         Today only kinda sux! But I'll get by, lol     0.5249\n",
       "13                      Make sure you :) or :D today!     0.8633\n",
       "14    Catch utf-8 emoji such as such as ğŸ’˜ and ğŸ’‹ and ğŸ˜     0.7003\n",
       "15                                     Not bad at all     0.4310"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "sentences = [\"VADER is smart, handsome, and funny.\",  \n",
    "             \"VADER is smart, handsome, and funny!\",  #å¸¦æ„Ÿå¹å·\n",
    "             \"VADER is very smart, handsome, and funny.\", \n",
    "             \"VADER is VERY SMART, handsome, and FUNNY.\",   #FUNNY.å¼ºè°ƒ\n",
    "             \"VADER is VERY SMART, handsome, and FUNNY!!!\",\n",
    "             \"VADER is VERY SMART, uber handsome, and FRIGGIN FUNNY!!!\", \n",
    "             \"VADER is not smart, handsome, nor funny.\",  \n",
    "             \"The book was good.\",  \n",
    "             \"At least it isn't a horrible book.\",  \n",
    "             \"The book was only kind of good.\", \n",
    "             \"The plot was good, but the characters are uncompelling and the dialog is not great.\", \n",
    "             \"Today SUX!\",  \n",
    "             \"Today only kinda sux! But I'll get by, lol\",  #lolç¼©ç•¥è¯­\n",
    "             \"Make sure you :) or :D today!\",  \n",
    "             \"Catch utf-8 emoji such as such as ğŸ’˜ and ğŸ’‹ and ğŸ˜\",  #emoji\n",
    "             \"Not bad at all\"  \n",
    "             ]\n",
    "\n",
    "def senti(text):\n",
    "    return analyzer.polarity_scores(text)['compound']\n",
    "\n",
    "df = pd.DataFrame(sentences)\n",
    "df.columns = ['text']\n",
    "#å¯¹textåˆ—ä½¿ç”¨sentiå‡½æ•°è¿›è¡Œæ‰¹å¤„ç†ï¼Œå¾—åˆ°çš„å¾—åˆ†èµ‹å€¼ç»™sentimentåˆ—\n",
    "df['sentiment'] = df.agg({'text':[senti]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ›´å¤š\n",
    "VADERç›®å‰åªæ”¯æŒè‹±æ–‡æ–‡æœ¬ï¼Œå¦‚æœæƒ³è¦å¯¹ä¸­æ–‡æ–‡æœ¬è¿›è¡Œåˆ†æï¼Œéœ€è¦åšä¸¤å¤§æ–¹é¢æ”¹åŠ¨ã€‚\n",
    "é¦–å…ˆè¦å°†åº“ä¸­çš„vaderSentiment.pyä¸­ç›¸åº”çš„è‹±æ–‡è¯è¯­æ”¹ä¸ºä¸­æ–‡è¯è¯­\n",
    "\n",
    "\n",
    "```python\n",
    "# (empirically derived mean sentiment intensity rating increase for booster words)\n",
    "B_INCR = 0.293\n",
    "B_DECR = -0.293\n",
    "\n",
    "# (empirically derived mean sentiment intensity rating increase for using ALLCAPs to emphasize a word)\n",
    "C_INCR = 0.733\n",
    "N_SCALAR = -0.74\n",
    "\n",
    "#å¦å®šè¯\n",
    "NEGATE = \\\n",
    "    [\"aint\", \"arent\", \"cannot\", \"cant\", \"couldnt\", \"darent\", \"didnt\", \"doesnt\",\n",
    "     \"ain't\", \"aren't\", \"can't\", \"couldn't\", \"daren't\", \"didn't\", \"doesn't\",\n",
    "     \"dont\", \"hadnt\", \"hasnt\", \"havent\", \"isnt\", \"mightnt\", \"mustnt\", \"neither\",\n",
    "     \"don't\", \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", \"mightn't\", \"mustn't\",\n",
    "     \"neednt\", \"needn't\", \"never\", \"none\", \"nope\", \"nor\", \"not\", \"nothing\", \"nowhere\",\n",
    "     \"oughtnt\", \"shant\", \"shouldnt\", \"uhuh\", \"wasnt\", \"werent\",\n",
    "     \"oughtn't\", \"shan't\", \"shouldn't\", \"uh-uh\", \"wasn't\", \"weren't\",\n",
    "     \"without\", \"wont\", \"wouldnt\", \"won't\", \"wouldn't\", \"rarely\", \"seldom\", \"despite\"]\n",
    "\n",
    "# booster/dampener 'intensifiers' or 'degree adverbs'\n",
    "# http://en.wiktionary.org/wiki/Category:English_degree_adverbs\n",
    "\n",
    "# æƒ…æ„Ÿå¼ºåº¦ å‰¯è¯\n",
    "BOOSTER_DICT = \\\n",
    "    {\"absolutely\": B_INCR, \"amazingly\": B_INCR, \"awfully\": B_INCR, \n",
    "     \"completely\": B_INCR, \"considerable\": B_INCR, \"considerably\": B_INCR,\n",
    "     \"decidedly\": B_INCR, \"deeply\": B_INCR, \"effing\": B_INCR, \"enormous\": B_INCR, \"enormously\": B_INCR,\n",
    "     ......\n",
    "     \"thoroughly\": B_INCR, \"total\": B_INCR, \"totally\": B_INCR, \"tremendous\": B_INCR, \"tremendously\": B_INCR,\n",
    "     \"uber\": B_INCR, \"unbelievably\": B_INCR, \"unusually\": B_INCR, \"utter\": B_INCR, \"utterly\": B_INCR,\n",
    "     \"very\": B_INCR,\n",
    "     \"almost\": B_DECR, \"barely\": B_DECR, \"hardly\": B_DECR, \"just enough\": B_DECR,\n",
    "     \"kind of\": B_DECR, \"kinda\": B_DECR, \"kindof\": B_DECR, \"kind-of\": B_DECR,\n",
    "     \"less\": B_DECR, \"little\": B_DECR, \"marginal\": B_DECR, \"marginally\": B_DECR,\n",
    "     \"occasional\": B_DECR, \"occasionally\": B_DECR, \"partly\": B_DECR,\n",
    "     \"scarce\": B_DECR, \"scarcely\": B_DECR, \"slight\": B_DECR, \"slightly\": B_DECR, \"somewhat\": B_DECR,\n",
    "     \"sort of\": B_DECR, \"sorta\": B_DECR, \"sortof\": B_DECR, \"sort-of\": B_DECR}\n",
    "\n",
    "# ä¸å†æƒ…æ„Ÿå½¢å®¹è¯è¯å…¸ä¸­ï¼Œä½†åŒ…å«æƒ…æ„Ÿä¿¡æ¯çš„ä¿šè¯­è¡¨è¾¾ï¼ˆç›®å‰è‹±æ–‡æ–¹é¢ä¹Ÿæœªå®Œæˆï¼‰\n",
    "SENTIMENT_LADEN_IDIOMS = {\"cut the mustard\": 2, \"hand to mouth\": -2,\n",
    "                          \"back handed\": -2, \"blow smoke\": -2, \"blowing smoke\": -2,\n",
    "                          \"upper hand\": 1, \"break a leg\": 2,\n",
    "                          \"cooking with gas\": 2, \"in the black\": 2, \"in the red\": -2,\n",
    "                          \"on the ball\": 2, \"under the weather\": -2}\n",
    "\n",
    "# åŒ…å«è¯å…¸å•è¯çš„ç‰¹æ®Šæƒ…å†µä¿šè¯­\n",
    "SPECIAL_CASE_IDIOMS = {\"the shit\": 3, \"the bomb\": 3, \"bad ass\": 1.5, \"badass\": 1.5,\n",
    "                       \"yeah right\": -2, \"kiss of death\": -1.5, \"to die for\": 3}\n",
    "```\n",
    "\n",
    "ç„¶åè¿˜è¦å°†è‹±æ–‡è¯å…¸ vader_lexicon.txtæ”¹ä¸ºå¯¹åº”æ ¼å¼çš„ä¸­æ–‡è¯å…¸ã€‚vader_lexicon.txtæ ¼å¼\n",
    "\n",
    "```\n",
    "TOKEN, MEAN-SENTIMENT-RATING, STANDARD DEVIATION, and RAW-HUMAN-SENTIMENT-RATINGS\n",
    "```\n",
    "\n",
    "### å¼•ç”¨ä¿¡æ¯\n",
    "å¦‚æœä½¿ç”¨VADERè¯å…¸ã€ä»£ç ã€æˆ–è€…åˆ†ææ–¹æ³•å‘è¡¨å­¦æœ¯æ–‡ç« ï¼Œè¯·æ³¨æ˜å‡ºå¤„ï¼Œæ ¼å¼å¦‚ä¸‹\n",
    "```\n",
    "Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.\n",
    "Refactoring for Python 3 compatibility, improved modularity, and incorporation into [NLTK] ...many thanks to Ewan & Pierpaolo.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
